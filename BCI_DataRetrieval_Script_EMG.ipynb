{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: mne in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (0.22.0)\nRequirement already satisfied: numpy>=1.11.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from mne) (1.19.2)\nRequirement already satisfied: scipy>=0.17.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from mne) (1.5.2)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import scipy.io as scipy\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install mne\n",
    "import mne\n",
    "from numpy import *\n",
    "from numpy.fft import *\n",
    "import scipy.signal as signal\n",
    "from matplotlib.pyplot import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    def _check_keys(d):\n",
    "        '''\n",
    "        checks if entries in dictionary are mat-objects. If yes\n",
    "        todict is called to change them to nested dictionaries\n",
    "        '''\n",
    "        for key in d:\n",
    "            if isinstance(d[key], scipy.matlab.mio5_params.mat_struct):\n",
    "                d[key] = _todict(d[key])\n",
    "        return d\n",
    "\n",
    "    def _todict(matobj):\n",
    "        '''\n",
    "        A recursive function which constructs from matobjects nested dictionaries\n",
    "        '''\n",
    "        d = {}\n",
    "        for strg in matobj._fieldnames:\n",
    "            elem = matobj.__dict__[strg]\n",
    "            if isinstance(elem, scipy.matlab.mio5_params.mat_struct):\n",
    "                d[strg] = _todict(elem)\n",
    "            elif isinstance(elem, np.ndarray):\n",
    "                d[strg] = _tolist(elem)\n",
    "            else:\n",
    "                d[strg] = elem\n",
    "        return d\n",
    "\n",
    "    def _tolist(ndarray):\n",
    "        '''\n",
    "        A recursive function which constructs lists from cellarrays\n",
    "        (which are loaded as numpy ndarrays), recursing into the elements\n",
    "        if they contain matobjects.\n",
    "        '''\n",
    "        elem_list = []\n",
    "        for sub_elem in ndarray:\n",
    "            if isinstance(sub_elem, scipy.matlab.mio5_params.mat_struct):\n",
    "                elem_list.append(_todict(sub_elem))\n",
    "            elif isinstance(sub_elem, np.ndarray):\n",
    "                elem_list.append(_tolist(sub_elem))\n",
    "            else:\n",
    "                elem_list.append(sub_elem)\n",
    "        return elem_list\n",
    "    data = scipy.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_all = loadmat('P2_AllLifts.mat')\n",
    "print( \"All Lifts loaded\")\n",
    "\n",
    "\n",
    "\n",
    "#these are the series we are looking at for subject 2. Everything except series 1 and 6\n",
    "trials_included=[2, 3, 4, 5, 7, 8, 9] \n",
    "\n",
    "#corresponding row indices in P.AllLifts where each series starts. Index is off by one bc of how python indexes things\n",
    "trialStartIdx = [28, 62, 96, 130, 192, 226, 260]\n",
    "\n",
    "#data structure to hold all EEG trials \n",
    "eeg_grasp_closed = []\n",
    "eeg_grasp_open = []\n",
    "emg_grasp_closed = []\n",
    "emg_grasp_open = []\n",
    "series_counter = 0\n",
    "trial_counter = 1\n",
    "i = 0\n",
    "for s in trials_included:\n",
    "    # load all the series specified in trials_included\n",
    "    series_filename = 'WS_P2_S{series}.mat'.format(series = s)\n",
    "    p_series = loadmat(series_filename)\n",
    "    print(\"Series data loaded\")\n",
    "    series_counter = series_counter + 1\n",
    "    print(\"series_counter: \", series_counter)\n",
    "\n",
    "    #identifying the starting row index in p.ALLLifts for the first trial of the current series\n",
    "    tStart = trialStartIdx[i]\n",
    "    i += 1\n",
    "    trial_counter = 1\n",
    "    #range for the for loop is 34 values bc there are 34 trials in each series\n",
    "    for trial_num in range(tStart, tStart + 34):\n",
    "        \n",
    "        #retrieving the point in time when both fingers touched object\n",
    "        #index values are one cloumn and one row before target value\n",
    "        tBothDigitTouch = np.array(p2_all['P']['AllLifts'])[trial_num, 14]\n",
    "        \n",
    "        tBothReleased = np.array(p2_all['P']['AllLifts'])[trial_num, 22]\n",
    "        \n",
    "        #converting time points to row indices to be accessed in windowed struct\n",
    "        #500 samples every second, so timepoint should be divided by 0.002\n",
    "        idxCloseEnd = int(tBothDigitTouch // 0.002) + int(0.8//0.002)\n",
    "        idxCloseStart = int(tBothDigitTouch // 0.002)- int(0.8//0.002)\n",
    "        \n",
    "        idxOpenEnd = int(tBothReleased // 0.002)+ int(0.8//0.002)\n",
    "        idxOpenStart = int(tBothReleased // 0.002)- int(0.8//0.002)\n",
    "        \n",
    "        idxCloseEndEMG = int(tBothDigitTouch // 0.0002) + int(0.8//0.0002)\n",
    "        idxCloseStartEMG = int(tBothDigitTouch // 0.0002) - int(0.8//0.0002)\n",
    "        \n",
    "        idxOpenEndEMG = int(tBothReleased // 0.0002) + int(0.8//0.0002)\n",
    "        idxOpenStartEMG = int(tBothReleased // 0.0002) - int(0.8//0.0002)\n",
    "\n",
    "        eeg_trial = np.array(p_series['ws']['win'][0]['eeg'])[idxCloseStart:idxCloseEnd].T \n",
    "        eeg_grasp_closed.append(eeg_trial)\n",
    "        \n",
    "        eeg_trial = np.array(p_series['ws']['win'][0]['eeg'])[idxOpenStart:idxOpenEnd].T \n",
    "        eeg_grasp_open.append(eeg_trial)\n",
    "        \n",
    "        emg_trial = np.array(p_series['ws']['win'][0]['emg'])[idxCloseStartEMG:idxCloseEndEMG].T \n",
    "        emg_grasp_closed.append(emg_trial)\n",
    "        \n",
    "        emg_trial = np.array(p_series['ws']['win'][0]['emg'])[idxOpenStartEMG:idxOpenEndEMG].T \n",
    "        emg_grasp_open.append(emg_trial)\n",
    "        #print(\"trial counter: \", trial_counter)\n",
    "        trial_counter = trial_counter +1\n",
    "                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = [2, 3, 4, 5, 7, 8, 9]\n",
    "eeg_close = {}\n",
    "counter = 0\n",
    "for i in range (0, len(series)):\n",
    "    new_list  = []\n",
    "    for s in range(34*(i-1), 34*i):\n",
    "        new_list.append(eeg_grasp_closed[s])\n",
    "    eeg_close[series[i]] = new_list\n",
    "#print(eeg_close.keys())\n",
    "#print(eeg_close.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = [2, 3, 4, 5, 7, 8, 9]\n",
    "eeg_open = {}\n",
    "counter = 0\n",
    "for i in range (0, len(series)):\n",
    "    new_list  = []\n",
    "    for s in range(34*(i-1), 34*i):\n",
    "        new_list.append(eeg_grasp_open[s])\n",
    "    eeg_open[series[i]] = new_list\n",
    "#print(eeg_open.keys())\n",
    "#print(eeg_open.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = [2, 3, 4, 5, 7, 8, 9]\n",
    "emg_close = {}\n",
    "counter = 0\n",
    "for i in range (0, len(series)):\n",
    "    new_list  = []\n",
    "    for s in range(34*(i-1), 34*i):\n",
    "        new_list.append(emg_grasp_closed[s])\n",
    "    emg_close[series[i]] = new_list\n",
    "#print(emg_close.keys())\n",
    "#print(emg_close.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = [2, 3, 4, 5, 7, 8, 9]\n",
    "emg_open = {}\n",
    "counter = 0\n",
    "for i in range (0, len(series)):\n",
    "    new_list  = []\n",
    "    for s in range(34*(i-1), 34*i):\n",
    "        new_list.append(emg_grasp_open[s])\n",
    "    emg_open[series[i]] = new_list\n",
    "#print(emg_open.keys())\n",
    "#print(emg_open.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = emg_close[2][0][4]\n",
    "print(test_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rectify(emg_data): \n",
    "    return abs(emg_data)\n",
    "\n",
    "def removeMean(emg_data): \n",
    "    return emg_data - np.mean(emg_data)\n",
    "\n",
    "def bandpass_filter(emg_data, sfreq, lowband, highband): \n",
    "    high_band = highband/(sfreq/2)\n",
    "    low_band = lowband/(sfreq/2)\n",
    "    b1, a1 = signal.butter(4, [high_band,low_band], btype='bandpass')\n",
    "    return signal.filtfilt(b1, a1, emg_data)\n",
    "\n",
    "def lowpass_filter(emg_data, sfreq, lowpass):\n",
    "    low_pass = lowpass/(sfreq/2)\n",
    "    b2, a2 = signal.butter(4, low_pass, btype='lowpass')\n",
    "    emg_envelope = signal.filtfilt(b2, a2, emg_data)\n",
    "    return emg_envelope\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing \n",
    "\n",
    "# remove mean\n",
    "emg_data = removeMean(test_arr)\n",
    "\n",
    "# bandpass filter\n",
    "emg_filtered = bandpass_filter(emg_data, 5000, 500, 5)\n",
    "\n",
    "# rectify data\n",
    "emg_rectified = rectify(emg_filtered)\n",
    "\n",
    "# lowpass filter \n",
    "emg_envelope = lowpass_filter(emg_rectified, 5000, 7)\n",
    "\n",
    "# plots after each preprocessing step\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4)\n",
    "fig.tight_layout()\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(10)\n",
    "fig.suptitle('EMG preprocessing')\n",
    "ax1.plot(time,test_arr)\n",
    "ax2.plot(time, emg_filtered)\n",
    "ax3.plot(time, emg_rectified)\n",
    "ax4.plot(time, emg_envelope)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db 16 wavelet object\n",
    "db16 = pywt.Wavelet('db16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi level wavlet decomposition\n",
    "cA2, cD4, cD4, cD3, cD2, cD1= pywt.wavedec(emg_envelope, db16, mode='symmetric', level=5)\n",
    "\n",
    "plt.plot(cA2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}